from nltk.tokenize import sent_tokenize,word_tokenize

example =["Hello Mr. Smith, how are you doing today? "
          "The weather is great, and Python is awesome. "
          "The sky is pinkish-blue. You shouldn't eat cardboard!"
          " I am so blue I'm greener than purple. "
          "I stepped on a Corn Flake, now I'm a Cereal Killer."
          " Everyday a grape licks a friendly cow. Look, a distraction! "
          "If your canoe is stuck in a tree with the headlights on, how many pancakes does it take to get to the moon"]
#print((example))
print(type(str(example)))
print(sent_tokenize(str(example))) #sent_tokenize function will segment paragraph into lines
print(word_tokenize(str(example))) #word_tokenize will split each word

